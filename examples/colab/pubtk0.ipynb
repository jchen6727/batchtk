{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen6727/colab/blob/master/j4/pubtk0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHio7AK092Ax"
      },
      "source": [
        "**Tutorial 0**\n",
        "\n",
        "**Note 0** This tutorial will set up a persistent virtual environment within Google Drive, install the development version of the `pubtk` python package to the persistent virtual environment and then demonstrate its use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dadp9J3EBYGf"
      },
      "source": [
        "**Note 0.1**\n",
        "To mount google drive and set up a virtual environment, we'll need to use the `google.colab.drive.mount()` function which comes as part of the preinstalled python packages in google colab (exists in every session), as well as `virtualenv` which does not come preinstalled, and needs to be installed either on a per-session basis through pip, or maintained within a separate persistent virtual environment\n",
        "\n",
        "**Note 0.2**\n",
        "if you already have created a virtual environment and the tutorial development environment in prior sessions, can skip executing cells `jupyter 1` through `jupyter 4` after executing `jupyter 0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RakTiLBY3i5H",
        "outputId": "1b7f87dc-57c4-4800-c0be-3c19f9e0e64c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#jupyter 0\n",
        "from google.colab import drive # use drive.mount() to link Google Drive to\n",
        "drive.mount('/content/drive')  # the google colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGIzGKGHDA5Y"
      },
      "source": [
        "**Note 1** The `!<command>` are executed in a new standalone shell (equivalent to running `<command>` within a newly opened terminal). The first installs virtualenv through pip, the second uses virtualenv to install a python environment that will be stored persistently on the linked Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYuT5rx3BZS_"
      },
      "outputs": [],
      "source": [
        "#jupyter 1\n",
        "!pip install virtualenv                  # install virtualenv to create a\n",
        "!virtualenv /content/drive/MyDrive/venv  # python environment within linked Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bVekIYhFb6M"
      },
      "source": [
        "**Note 2** when using google colab, because `!<command>` is executed in a new standalone shell, any persistent changes (such as `!cd`) are lost when the line completes. One workaround is using `;` to execute multiple script calls within one command, as well as `;\\` which allows you to escape the newline. However, keep in mind that shell commands are finicky with spacing   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTiFNkNRF-c7"
      },
      "outputs": [],
      "source": [
        "#jupyter 2\n",
        "!cd /content/drive/MyDrive\n",
        "!pwd                           # prints /content\n",
        "!cd /content/drive/MyDrive;\\\n",
        "pwd;\\\n",
        "echo $(pwd)                    # prints /content/drive/MyDrive, twice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as5gb1LyIFi5"
      },
      "source": [
        "**Note 3** One way of using our virtualenv is sourcing the activation script prior to any `python` or `pip` `!<command>`; another is by specifying the full path to the binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWcgRLi7IE_Q"
      },
      "outputs": [],
      "source": [
        "#jupyter 3\n",
        "!source /content/drive/MyDrive/venv/bin/activate #doesn't do anything so...\n",
        "!which python #the python command still points to the default, instead use...\n",
        "!source /content/drive/MyDrive/venv/bin/activate;which python\n",
        "#which will call the venv python, or use a static path for python/pip etc.\n",
        "!which /content/drive/MyDrive/venv/bin/python #venv python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA66QVKwK7H2"
      },
      "source": [
        "**Note 4** now that we are familiarized with `!<command>` and the `virtualenv`, we will create our workspace for experimenting with the `pubtk` package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MHt-_54EEBV"
      },
      "outputs": [],
      "source": [
        "#jupyter 4\n",
        "!mkdir /content/drive/Mydrive/dev\n",
        "!git clone --depth 1 https://github.com/jchen6727/pubtk.git /content/drive/MyDrive/dev/pubtk\n",
        "!/content/drive/MyDrive/venv/bin/pip install -e /content/drive/MyDrive/dev/pubtk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmvbCZS_MQLS"
      },
      "source": [
        "**Note 5** after establishing the virtual environment, we need to link the packages in the virtual environment to the current `google colab` jupyter notebook session. This can be done by adding the virtual environment packages to our search path with `site.addsitedir()` after which we are free to use packages from our python virtual environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLlNUJX-HHMX"
      },
      "outputs": [],
      "source": [
        "#jupyter 5\n",
        "import site\n",
        "site.addsitedir('/content/drive/MyDrive/venv/lib/python3.10/site-packages')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8T_A8BZNgQY"
      },
      "source": [
        "**Note 6** the `pubtk` package was designed with SOLID OOP principles in mind. Rather than using arguments to augment the control flow of a monolithic function, multiple classes allow for dynamic execution of relevant code.\n",
        "The `base classes` which other classes inherit from include:\n",
        "\n",
        "**Runner** which implements functionality for parsing provided `arguments` into any arbitrary scripts namespace and communicating with the **Dispatcher**\n",
        "\n",
        "**Dispatcher**: which implements functionality for updating the **Submit** with `arguments`, calling **Submit** functions to execute the appropriate arbitrary script containing the **Runner** class, and monitoring the execution of of the arbitrary script\n",
        "\n",
        "**Submit** which implements functionality for serializing the `arguments` to pass to the **Runner**, updating the **Template** with the `arguments` and communication protocols for use between the **Dispatcher** and **Runner**, and starting the arbitrary script containing the **Runner** class\n",
        "\n",
        "**Template** which implements functionality for generating and formatting arbitrary string templates for **Submit**\n",
        "\n",
        "Other classes `extend and inherit` these `base classes`, allowing for more complex interactions, for instance, by adding custom scripting, support for custom communication protocols (`stdio`, `filesystem`, `socket`), etc.\n",
        "\n",
        "Let's look at these classes, including the `base classes` and custom `extended classes`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9nf9qhwL4so"
      },
      "outputs": [],
      "source": [
        "#jupyter 6\n",
        "from pubtk.runtk import Runner, SocketRunner, FileRunner, INET_Dispatcher, SH_Dispatcher, Template, Submit, ZSHSubmitSOCK\n",
        "sockrunner = SocketRunner() # SocketRunner inherits Runner and extends it with functionality for communicating through socket.socket functions\n",
        "filerunner = FileRunner()   # FileRunner inherits Runner and extends it with functionality for communicating through file I/O\n",
        "dispatcher = INET_Dispatcher(submit = ZSHSubmitSOCK()) # Dispatcher requires instantiation of a Submit object, inherits Dispatcher and extends it with functionality for communicating through file socket.socket functions related to INET (TCP) protocol\n",
        "template = Template(\"\"\"{foo}, {bar}, {baz}\"\"\") # Template requires a string to call\n",
        "submit = Submit(submit_template=template, script_template=template) #Submit requires both a submit and script template (both are Template instances)\n",
        "zsh = ZSHSubmitSOCK() #ZSHSubmitSOCK is a custom class inheriting submit which uses .zsh scripts to execute code and establishes handling for socket.socket communications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXXVKZCAYrxd"
      },
      "source": [
        "**Note 7** Using the `help()` function on any of these classes helps demonstrate both the base functionality and extended functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdZuf5K_U_rT"
      },
      "outputs": [],
      "source": [
        "#jupyter 7\n",
        "help(Submit)\n",
        "dir(Submit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFI0_zY6ZK5M"
      },
      "source": [
        "**Note 8** Let's look closer at the custom submit `ZSHSubmitSock` by printing the generated instance\n",
        "\n",
        "Note that it uses the base `__repr__` from `Submit` to handle print statements (verify this with `help()`), it shows the command executed by the Submit to call the arbitrary script, the script file that will be run, as well as the contents of the script file.\n",
        "\n",
        "special arguments (`cwd`, `label` and `env`) will be automatically handled by the **Dispatcher** and **Submit** prior to job creation by default. `env` specifically will be filled with the serialized arguments for the **Runner**. (`sockname`) is a unique argument that allows for establishing communication between specialized **Dispatcher** and **Runner** scripts. It is handled by **Dispatcher** automatically. (`command`) is something that is updated to our preference (i.e. to some variant of `mpiexec -np 4 nrniv...` or some other call)\n",
        "\n",
        "**Note 8.1**\n",
        "notice the use of `nohup` which prevents blocking by the `{command}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lobFffJ_cvJR"
      },
      "outputs": [],
      "source": [
        "#jupyter 8\n",
        "print(zsh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiq_ZYd9Zz1y"
      },
      "source": [
        "**Note 9**\n",
        "Now lets create a custom submission class that can handle executing arbitrary scripts in a `Google Colab` environment. For instance, we know that the command to call for the appropriate python script needs to be statically linked to our `virtualenv` and the script as well needs to be referenced from the `/content` root. Additionally, we can say that we arbitrarily want to have some `FOO`, `BAR`, `BAZ` values passed to the environment, to be defined by our `Dispatcher` and we want it to provide a `process ID` (`pid`) to `stdout` and then capture that `stdout` and return it as a `job_id`.\n",
        "\n",
        "again, by inheriting from `Submit`, we preserve the original functionality and relevant interfaces, and then extend with our own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPlK_zn6gcZv"
      },
      "outputs": [],
      "source": [
        "#jupyter 9\n",
        "class GCSubmit(Submit):\n",
        "  def __init__(self):\n",
        "    # creates a Submit with the templates we define\n",
        "    super().__init__(\n",
        "        submit_template = Template(\"sh {cwd}/{label}.sh\"),\n",
        "        script_template = Template(\"\"\"\\\n",
        "#!/bin/bash\n",
        "export FOO={foovalue}\n",
        "export BAR={barvalue}\n",
        "export BAZ={bazvalue}\n",
        "{env}\n",
        "nohup /content/drive/MyDrive/venv/bin/python /content/drive/MyDrive/dev/runner.py > {cwd}/{label}.run &\n",
        "pid=$!\n",
        "echo $pid >&1\n",
        "\"\"\"\n",
        "        )\n",
        "    )\n",
        "  def submit_job(self):\n",
        "    # using this submit_job, we can add some handling of stdout, job failure (i.e. if stdout does not return an integer value as expected),\n",
        "    # extending the functionality of Submit with this exception handling.\n",
        "    proc = super().submit_job()\n",
        "    try:\n",
        "      self.job_id = int(proc.stdout)\n",
        "    except Exception as e:\n",
        "      raise(Exception(\"{}\\nJob submission failed:\\n{}\\n{}\\n{}\\n{}\".format(e, self.submit, self.script, proc.stdout, proc.stderr)))\n",
        "    return self.job_id\n",
        "\n",
        "gcs = GCSubmit()\n",
        "print(gcs) # inherited functionality from the base Submit class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgYwO0zOh64Z"
      },
      "source": [
        "**Note 10** Now we can pass the custom submission to our **SH_Dispatcher** which extends the base **Dispatcher** with support for `shell` (/`bash`/`powershell`/`z shell` ...) scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmsW8WnQ1ZDF"
      },
      "outputs": [],
      "source": [
        "#jupyter 10\n",
        "dispatcher = SH_Dispatcher(cwd='/content', submit=gcs, gid='example')\n",
        "print(dispatcher.submit) # prints the dispatcher.submit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQabG58KjEeF"
      },
      "source": [
        "**Note 11** To pass arguments to the **Runner** script, we will call `update_env` from the dispatcher. The argument is a dictionary of `key:value` pairs. Additionally, we can update the arbitrary `FOO`, `BAR` and `BAZ` values from the `dispatcher.submit`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4aOkYP8NNkL"
      },
      "outputs": [],
      "source": [
        "#jupyter 11\n",
        "dispatcher.update_env({'strvalue': '1',\n",
        "                       'intvalue': 2,\n",
        "                       'fltvalue': 3.0})\n",
        "dispatcher.submit.update_templates(foovalue='\"A\"',\n",
        "                                   barvalue='\"B\"',\n",
        "                                   bazvalue='\"C\"')\n",
        "print(dispatcher.submit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCjrbtEanO1L"
      },
      "source": [
        "**Note 12** Upon job creation, the `{env}`, `{cwd}` and `{label}` are filled.\n",
        "\n",
        "the `{env}` will be replaced with a custom `serialization` (in this case, exported string values) that can then be deserialized by the **runner** in the `runner.py` script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lKwvcaSOot7"
      },
      "outputs": [],
      "source": [
        "#jupyter 12\n",
        "dispatcher.create_job()\n",
        "print(dispatcher.submit) # see the new submit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q8an5R0qUns"
      },
      "source": [
        "**Note 13** Let's download and check a basic `runner.py` using the `Runner` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cEm0uh6ZqgB7",
        "outputId": "ec096e06-876b-4606-be85-cc14519f41bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    14  100    14    0     0     50      0 --:--:-- --:--:-- --:--:--    51\n",
            "404: Not Found"
          ]
        }
      ],
      "source": [
        "#jupyter 13\n",
        "!rm /content/drive/MyDrive/dev/runner.py\n",
        "!curl https://raw.githubusercontent.com/jchen6727/colab/master/j4/basic_runner.py > /content/drive/MyDrive/dev/runner.py\n",
        "!cat /content/drive/MyDrive/dev/runner.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjnpvyPLxsR0"
      },
      "source": [
        "**Note 14** Notice that the runner.py script automatically captures the `arguments` passed in `{env}` in the `runner.mappings` attribute as a dictionary of `key:value` pairs. We'll have it print the job ID with `os.getpid()` and then print the `arguments` passed to it, which we will be able to see in `/content/example.run` after submitting the job via the `dispatcher.submit_job()` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIaw01n5O5Zq"
      },
      "outputs": [],
      "source": [
        "#jupyter 14\n",
        "dispatcher.submit_job()\n",
        "dispatcher.job_id # prints the job_id, should match the printed pid from the runner.py script"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}